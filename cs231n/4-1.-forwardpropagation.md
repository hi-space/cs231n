# 4-1. Forwardpropagation

![](../.gitbook/assets/image%20%28176%29.png)



| **Var** | **Name** | **Dimensions** | **Explanation** |
| :--- | :--- | :--- | :--- |
| `X` | Input | \(3, 1\) | Includes 3 rows of training data, and each row has 1 attribute \(height, price, etc.\) |
| `Wh` | Hidden weights | \(1, 2\) | These dimensions are based on number of rows equals the number of attributes for the observations in our training set. The number columns equals the number of neurons in the hidden layer. The dimensions of the weights matrix between two layers is determined by the sizes of the two layers it connects. There is one weight for every input-to-neuron connection between the layers. |
| `Bh` | Hidden bias | \(1, 2\) | Each neuron in the hidden layer has is own bias constant. This bias matrix is added to the weighted input matrix before the hidden layer applies ReLU. |
| `Zh` | Hidden weighted input | \(1, 2\) | Computed by taking the dot product of X and Wh. The dimensions \(1,2\) are required by the rules of matrix multiplication. Zh takes the rows of in the inputs matrix and the columns of weights matrix. We then add the hidden layer bias matrix Bh. |
| `H` | Hidden activations | \(3, 2\) | Computed by applying the Relu function to Zh. The dimensions are \(3,2\) — the number of rows matches the number of training samples and the number of columns equals the number of neurons. Each column holds all the activations for a specific neuron. |
| `Wo` | Output weights | \(2, 2\) | The number of rows matches the number of hidden layer neurons and the number of columns equals the number of output layer neurons. There is one weight for every hidden-neuron-to-output-neuron connection between the layers. |
| `Bo` | Output bias | \(1, 2\) | There is one column for every neuron in the output layer. |
| `Zo` | Output weighted input | \(3, 2\) | Computed by taking the dot product of H and Wo and then adding the output layer bias Bo. The dimensions are \(3,2\) representing the rows of in the hidden layer matrix and the columns of output layer weights matrix. |
| `O` | Output activations | \(3, 2\) | Each row represents a prediction for a single observation in our training set. Each column is a unique attribute we want to predict. Examples of two-column output predictions could be a company’s sales and units sold, or a person’s height and weight. |

{% embed url="https://ml-cheatsheet.readthedocs.io/en/latest/forwardpropagation.html" %}



