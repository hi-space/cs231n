# Markov Decision Processes

## Markov Processes

환경이 fully observable 할 때 MDP 가 된다. 모든 강화학습 문제는 MDP 형태로 만들 수 있다.

### Markov Property

![Markov](../.gitbook/assets/image%20%28261%29.png)

{% hint style="info" %}
The future is independent of the past given the present
{% endhint %}

state는 미래의 충분한 통계이다.

### State Transition Matrix



